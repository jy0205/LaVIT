{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "from models import build_model\n",
    "from PIL import Image\n",
    "from IPython.display import Image as ipython_image\n",
    "from diffusers.utils import load_image, export_to_video, export_to_gif"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building the Video-LaVIT Model and Load the checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The local directory to save Video-LaVIT checkpoint\n",
    "model_path = \"/home/jinyang06/models/VideoLaVIT-v1\"\n",
    "model_dtype='fp16'\n",
    "\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# Set the load GPU id\n",
    "device_id = 0\n",
    "torch.cuda.set_device(device_id)\n",
    "device = torch.device('cuda')\n",
    "\n",
    "# If you have already install xformers, set `use_xformers=True` to save the GPU memory (Xformers is not supported on V100 GPU)\n",
    "# If you have already download the checkpoint, set `local_files_only=True`` to avoid auto-downloading from remote\n",
    "model = build_model(model_path=model_path, model_dtype=model_dtype, local_files_only=True, \n",
    "                device_id=device_id, use_xformers=True, understanding=False,)\n",
    "model = model.to(device)\n",
    "\n",
    "print(\"Building Model Finsished\")\n",
    "torch_dtype = torch.bfloat16 if model_dtype==\"bf16\" else torch.float16"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text-to-Video Generation\n",
    "\n",
    "Video-LaVIT is trained on the open-sourced Webvid-10M dataset, where the videos have watermark. Therefore, it may generate a keyframe with a watermark and infects the aesthetic of the generated video. If you want to generate video without watermark, we recommend you to try the video_generation_aest.ipynb, where we intervene the keyframe by a text-to-image model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"FPV drone footage of an ancient city in autumn\"\n",
    "# prompt = 'A steaming cup of coffee with mountains in the background. Resting during road trip'\n",
    "# prompt = 'Bloomming cherry tree in the garden beautiful sun light'\n",
    "# prompt = 'Golden retriever puppy running in the park. Autumn. Beautiful leaves on the ground'\n",
    "# prompt = 'Back view on young woman dressed in a bright yellow jacket walk in outdoor forest'\n",
    "# prompt = 'Sailboat sailing on a sunny day in a mountain lake'\n",
    "# prompt = \"Onboard camera view of bike riding on country asphalt road through picturesque villages\"\n",
    "# prompt = \"A man was riding his motorcycle on the highway\"\n",
    "# prompt = \"A dog driving a car on a suburban street wearing funny sunglasses\"\n",
    "# prompt = \"A boat sailing leisurely along the Seine River with the Eiffel Tower in background by Vincent van Gogh\"\n",
    "# prompt = \"A spaceship is slowly descending\"\n",
    "# prompt = \"A girl is writing something on a book, Oil painting style\"\n",
    "# prompt = \"Waves crashing against a lone lighthouse, ominous lighting\"\n",
    "# prompt = \"A bright fire burns in the stone oven\"\n",
    "# prompt = \"Aurora Borealis Green Loop Winter Mountain Ridges Northern Lights\"\n",
    "# prompt = \"a white swan moving on the lake\"\n",
    "\n",
    "# The keyframe aspect ratio you want to generate\n",
    "# Only support two ratios: square and widescreen video\n",
    "ratio_dict = {\n",
    "    '1:1' : (1024, 1024),\n",
    "    '1:2' : (576, 1024),\n",
    "}\n",
    "\n",
    "print(prompt)\n",
    "\n",
    "ratio = '1:2'\n",
    "height, width = ratio_dict[ratio]\n",
    "\n",
    "# The video width and height should has the same aspect ratio with the generated keyframe\n",
    "# Generated high resolution video requires more GPU memory, you can choose to lower the resolution.\n",
    "# e.g., set video_width=576, video_height = 320 for 1:2;  video_width=512, video_height = 512 for 1:1\n",
    "\n",
    "if ratio == '1:2':\n",
    "    video_width = 896\n",
    "    video_height = 512\n",
    "    # video_width = 576\n",
    "    # video_height = 320\n",
    "else:\n",
    "    assert ratio == '1:1'\n",
    "    video_width = 768\n",
    "    video_height = 768\n",
    "    # video_width = 512\n",
    "    # video_height = 512\n",
    "\n",
    "\n",
    "with torch.cuda.amp.autocast(enabled=True, dtype=torch_dtype):\n",
    "    videos, keyframes = model.generate_video(prompt, width=width, height=height, num_return_images=1, \n",
    "            video_width=video_width, video_height=video_height, guidance_scale_for_llm=4.0, \n",
    "            guidance_scale_for_decoder=7.0, num_inference_steps=50, top_k=50,)\n",
    "\n",
    "\n",
    "export_to_gif(videos[0], \"tmp/generated.gif\")\n",
    "display(ipython_image(open('tmp/generated.gif','rb').read()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image-to-Video Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = 'demo/catus1.jpg'\n",
    "# image_path = 'demo/scene.jpg'\n",
    "# image_path = 'demo/girl.jpg'\n",
    "\n",
    "image = Image.open(image_path).convert(\"RGB\")\n",
    "display(image)\n",
    "input_prompts = [(image, 'image')]\n",
    "\n",
    "if image.width > image.height:\n",
    "    video_width = 896; video_height = 512\n",
    "else:\n",
    "    video_width = 768; video_height = 768\n",
    "\n",
    "with torch.cuda.amp.autocast(enabled=True, dtype=torch_dtype):\n",
    "    videos, _ = model.multimodal_video_generate(input_prompts, video_width=video_width, video_height=video_height, \n",
    "            guidance_scale_for_llm=4.0, top_k=50,)\n",
    "\n",
    "export_to_gif(videos[0], \"tmp/generated.gif\")\n",
    "display(ipython_image(open('tmp/generated.gif','rb').read()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Long Video Generation\n",
    "\n",
    "It will takes long time to generate long video; We set the video_width and video_height to low resolution (576, 320) by default; The clip_num is the generated video clip numbers. Since the model is trained on video less than 10s, when clip number > 3, the video quality severely degradates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = 'Back view on young woman dressed in a bright yellow jacket walk in outdoor forest'\n",
    "# prompt = \"Onboard camera view of bike riding on country asphalt road through picturesque villages\"\n",
    "# prompt = 'Sailboat sailing on a sunny day in a mountain lake'\n",
    "# prompt = 'A steaming cup of coffee with mountains in the background. Resting during road trip'\n",
    "# prompt = \"A bright fire burns in the stone oven\"\n",
    "# prompt = \"A dog in the sun\"\n",
    "\n",
    "\n",
    "ratio_dict = {\n",
    "    '1:1' : (1024, 1024),\n",
    "    '1:2' : (576, 1024),\n",
    "}\n",
    "\n",
    "print(prompt)\n",
    "\n",
    "# The keyframe aspect ratio you want to generate\n",
    "ratio = '1:2'\n",
    "height, width = ratio_dict[ratio]\n",
    "\n",
    "# The video width and height should has the same aspect ratio with the generated keyframe\n",
    "if ratio == '1:2':\n",
    "    # video_width = 1024\n",
    "    # video_height = 576\n",
    "    video_width = 576\n",
    "    video_height = 320\n",
    "else:\n",
    "    assert ratio == '1:1'\n",
    "    # video_width = 768\n",
    "    # video_height = 768\n",
    "    video_width = 512\n",
    "    video_height = 512\n",
    "\n",
    "# The generated video clip numbers\n",
    "clip_num = 2\n",
    "\n",
    "with torch.cuda.amp.autocast(enabled=True, dtype=torch_dtype):\n",
    "    videos, frames = model.generate_video(prompt, width=width, height=height, num_return_images=1, \n",
    "        video_width=576, video_height=320, guidance_scale_for_llm=4.0, guidance_scale_for_decoder=7.0, \n",
    "        num_inference_steps=50, top_k=50, clip_num=clip_num, inverse_rate=0.9,\n",
    "    )\n",
    "\n",
    "clip_videos = videos[0][:24]\n",
    "for i_clip in range(1, clip_num):\n",
    "    clip_videos += videos[0][i_clip * 24 + 1:i_clip * 24 + 24]\n",
    "\n",
    "export_to_gif(clip_videos, \"tmp/generated.gif\")\n",
    "display(ipython_image(open(\"tmp/generated.gif\",'rb').read()))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text-to-image Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"a high contrast photo of an astronaut riding a horse in the forest.\"\n",
    "# prompt = \"A high contrast photo of panda dressed as an astronaut sits at a table in a photorealistic style\"\n",
    "# prompt = \"a sculpture of a duck made of wool\"\n",
    "# prompt = \"Cute adorable little goat, unreal engine, cozy interior lighting, art station, detailed digital painting, cinematic, octane rendering\"\n",
    "# prompt = 'a super math wizard cat, richly textured oil painting'\n",
    "# prompt = \"A oil painting of a female painter with a brush in hand, white background, painting, looking very powerful\"\n",
    "\n",
    "\n",
    "ratio_dict = {\n",
    "    '1:1' : (1024, 1024),\n",
    "    '4:3' : (896, 1152),\n",
    "    '3:2' : (832, 1216),\n",
    "    '16:9' : (768, 1344),\n",
    "    '2:3' : (1216, 832),\n",
    "    '3:4' : (1152, 896),\n",
    "    '1:2' : (576, 1024),\n",
    "}\n",
    "\n",
    "print(prompt)\n",
    "ratio = '1:1'\n",
    "height, width = ratio_dict[ratio]\n",
    "\n",
    "with torch.cuda.amp.autocast(enabled=True, dtype=torch_dtype):\n",
    "    images = model.generate_image(prompt, width=width, height=height, num_return_images=1, \n",
    "        guidance_scale_for_llm=4.0, guidance_scale_for_decoder=7.0, num_inference_steps=50, top_k=50, temperature=1.0)\n",
    "\n",
    "display(images[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
